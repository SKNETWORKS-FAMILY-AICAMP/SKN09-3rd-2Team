{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TOKENIZERS_PARALLELISM=false\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install typing_extensions pydantic openai\n",
    "!pip install datasets transformers peft trl bitsandbytes\n",
    "!pip install sentence-transformers langchain langchain_community\n",
    "!pip install chromadb\n",
    "#!pip uninstall numpy -y\n",
    "# !pip install numpy==1.26.4\n",
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langsmith import Client\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Pipeline ëž˜í•‘\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# ìž„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "vector_store = Chroma(\n",
    "    persist_directory=\"chroma_index\",\n",
    "    embedding_function=embedding\n",
    ")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# âœ… ì‚¬ìš©ìž ì •ì˜ í”„ë¡¬í”„íŠ¸\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "        ë„ˆëŠ” í•­ê³µê¸° ë°˜ìž… ê¸ˆì§€ ë° ì œí•œ ë¬¼í’ˆì— ëŒ€í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ë‹µí•´ì£¼ê³  ë‚˜ë¼ë³„ ì—¬í–‰ì§€ ì¶”ì²œ ë° ë¬¸í™”ì°¨ì´ë¥¼ ìž˜ ì„¤ëª…í•  ìˆ˜ ìžˆì–´\n",
    "        ë¬¸ë§¥ì— í•´ë‹¹ í•˜ëŠ” ë‚´ìš©ë“¤ë§Œ ì‹ ë¢°ë„ìžˆê²Œ ëŒ€ë‹µí•´ì•¼í•´\n",
    "\n",
    "        ### ì§ˆë¬¸:\n",
    "        {question}\n",
    "        \n",
    "        ### ë¬¸ë§¥:\n",
    "        {context}\n",
    "\n",
    "        ### ë‹µë³€:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# JSON íŒŒì¼ ë¡œë“œ\n",
    "with open(\"test_case.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_cases = test_data[\"test_cases\"]\n",
    "\n",
    "# RetrievalQA ì²´ì¸ êµ¬ì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "for test in test_cases:\n",
    "    print(f\"\\n[í…ŒìŠ¤íŠ¸ ID: {test['id']}]\")\n",
    "    print(f\"ì§ˆë¬¸: {test['question']}\")\n",
    "    expected = test[\"expected_answer\"]\n",
    "    \n",
    "    # ëª¨ë¸ ì‘ë‹µ ì–»ê¸°\n",
    "    result = qa_chain.run(test[\"question\"])\n",
    "    \n",
    "    print(f\"âœ… ê¸°ëŒ€ ì‘ë‹µ: {expected}\")\n",
    "    print(f\"ðŸ¤– ëª¨ë¸ ì‘ë‹µ: {result[\"result\"].split(\"### ë‹µë³€:\\n\")[-1].strip()}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
